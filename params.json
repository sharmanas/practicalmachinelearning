{"name":"Practicalmachinelearning","tagline":"Repository for JHU Coursera Practical Machine Learning Project","body":"---\r\ntitle: \"Qualitative Assessment of Exercising\"\r\nauthor: \"Manas Sharma\"\r\ndate: \"March 12, 2016\"\r\noutput: html_document\r\n---\r\n\r\nUsing devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement â€“ a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, we use data from accelerometers on the belt, forearm, arm, and dumbbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. Given the data from accelerometers, the goal is to predict the class of action (variable `classe`) which can be one of the following:  \r\n\r\n* exactly according to the specification (A)\r\n* throwing elbows to the front (B)\r\n* lifting the dumbbell only halfway (C)\r\n* lowering the dumbbell only halfway (D)\r\n* throwing the hips to the front (E)\r\n  \r\nMore information is available from the website [here](http://groupware.les.inf.puc-rio.br/har) (see the section on the Weight Lifting Exercise Dataset).  \r\n\r\n## Data  \r\nThe training and test data for this project are available [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv) and [here](https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv), respectively.  \r\n```{r, cache=TRUE, message=FALSE}\r\nlibrary(RCurl)\r\ntrain.url <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\"\r\ntest.url <- \"https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\"\r\ntrain.data <- read.csv(text=getURL(train.url), na.strings=c(\"\", \"NA\"))\r\ntest.data <- read.csv(text=getURL(test.url), na.strings=c(\"\", \"NA\"))\r\n```\r\nThe first column is the Index variable and hence can be omitted from the data set.  \r\n```{r}\r\ntrain.data$X <- NULL\r\n```\r\nSimilarly, the user and time information should not have any effect on whether barbell lifts are performed correctly or not.\r\n```{r}\r\ncol.rm <- c(\"user_name\", \"raw_timestamp_part_1\",\r\n                    \"raw_timestamp_part_2\", \"cvtd_timestamp\")\r\nfor (col in col.rm) {\r\n    train.data[, col] <- NULL\r\n}\r\n```\r\nMany of the columns in the data set have majority of missing values. Therefore, we will remove these columns (or, features) from our training and test data sets since imputation is not an option.\r\n```{r}\r\ncol.NAs <- apply(train.data, 2, function(x) {sum(is.na(x))})\r\ntrain.data <- train.data[, which(col.NAs == 0)]\r\n```\r\nSome of the variables have near constant values, i.e. almost zero variance. Hence, we can remove these zero variance predictors from our data since they have few unique values relative to the number of observations.\r\n```{r, message=FALSE}\r\nlibrary(caret)\r\nnsv <- nearZeroVar(train.data)\r\ntrain.data <- train.data[-nsv]\r\ntest.data <- test.data[-nsv]\r\n```\r\nThe final set of predictors used for classification are:\r\n```{r}\r\nnames(train.data)\r\n```\r\n\r\n## Model  \r\nWe will use Random Forest classifier to predict the action class. To measure the accuracy of the model, we will perform a 10-fold cross validation with 80:20 split on each fold, i.e. 80% of the data will be used for training and remaining 20% will be used for testing.\r\n```{r, cache=TRUE, message=FALSE}\r\nlibrary(randomForest)\r\nset.seed(123)\r\nobs <- c()\r\npreds <- c()\r\nfor(i in 1:10) {\r\n    intrain = sample(1:dim(train.data)[1], size=dim(train.data)[1] * 0.8, replace=F)\r\n    train.cross = train.data[intrain,]\r\n    test.cross = train.data[-intrain,]\r\n    rf <- randomForest(classe ~ ., data=train.cross)\r\n    obs <- c(obs, test.cross$classe)\r\n    preds <- c(preds, predict(rf, test.cross))\r\n}\r\n```\r\nThe confusion matrix for predictions on cross validation folds is:\r\n```{r}\r\nconf.mat <- confusionMatrix(table(preds, obs))\r\nconf.mat$table\r\n```\r\nThe model seems to be classifying well enough, with the accuracy of `r round(conf.mat$overall[[1]]*100, 2)`%. Finally, let's train the random forest on the entire data set so that the model can be used to predict the class of an action, given a set of activity measurements.\r\n```{r, cache=TRUE, message=FALSE}\r\nlibrary(randomForest)\r\nmodel <- randomForest(classe ~ ., data=train.data)\r\n```","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}